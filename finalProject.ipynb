{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing for this data set is quite simple, as the dataset already contains tags_tokenized to eliminate unnecesary words from the data set. Additionally, all numerical values are already scaled between 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colez\\anaconda3\\envs\\cosc410\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t Avg Train Loss: 0.07135\t Avg Val Loss: 0.07071\n",
      "Epoch 6:\t Avg Train Loss: 0.0593\t Avg Val Loss: 0.05472\n",
      "Epoch 11:\t Avg Train Loss: 0.04061\t Avg Val Loss: 0.03775\n",
      "Epoch 16:\t Avg Train Loss: 0.03369\t Avg Val Loss: 0.03181\n",
      "[array([0.08239034], dtype=float32), array([0.2038505], dtype=float32), array([0.2214025], dtype=float32), array([0.26399422], dtype=float32), array([0.27773845], dtype=float32), array([0.28787023], dtype=float32), array([0.29999214], dtype=float32), array([0.29976588], dtype=float32), array([0.30272347], dtype=float32), array([0.29865143], dtype=float32), array([0.29940924], dtype=float32), array([0.29992396], dtype=float32), array([0.29911944], dtype=float32), array([0.29911873], dtype=float32), array([0.2990963], dtype=float32), array([0.29917264], dtype=float32), array([0.2990887], dtype=float32), array([0.29907805], dtype=float32), array([0.2990942], dtype=float32), array([0.29911152], dtype=float32), array([0.2991236], dtype=float32), array([0.29912168], dtype=float32), array([0.2991211], dtype=float32), array([0.29911992], dtype=float32), array([0.2991209], dtype=float32), array([0.2991215], dtype=float32), array([0.29912177], dtype=float32), array([0.2991218], dtype=float32), array([0.29912177], dtype=float32), array([0.2991219], dtype=float32), array([0.29912186], dtype=float32), array([0.29912192], dtype=float32), array([0.29912186], dtype=float32), array([0.2991219], dtype=float32), array([0.29912192], dtype=float32), array([0.29912192], dtype=float32), array([0.2991219], dtype=float32), array([0.29912192], dtype=float32), array([0.29912192], dtype=float32), array([0.2991219], dtype=float32), array([0.2991219], dtype=float32), array([0.29912195], dtype=float32), array([0.2991219], dtype=float32), array([0.29912186], dtype=float32), array([0.29912192], dtype=float32), array([0.29912192], dtype=float32), array([0.2991219], dtype=float32), array([0.29912192], dtype=float32), array([0.2991219], dtype=float32), array([0.29912183], dtype=float32)]\n",
      "[0.13636364, 0.13636364, 0.4090909, 0.13636364, 0.90909094, 0.36363637, 0.3181818, 0.22727273, 0.13636364, 0.0, 0.13636364, 0.36363637, 0.45454547, 0.3181818, 0.13636364, 0.22727273, 0.0, 0.27272728, 0.13636364, 0.0, 0.18181819, 0.045454547, 0.0, 0.045454547, 0.36363637, 0.5, 0.6818182, 0.3181818, 0.22727273, 0.3181818, 0.36363637, 0.045454547, 0.22727273, 0.5, 0.3181818, 0.18181819, 0.18181819, 0.0, 0.4090909, 0.3181818, 0.045454547, 0.22727273, 0.0, 0.22727273, 0.13636364, 0.22727273, 0.18181819, 0.3181818, 0.22727273, 0.4090909]\n",
      "0.03556999\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")\n",
    "import pandas as pd\n",
    "from DataProcessor import *\n",
    "from RNNmodel import *\n",
    "from util import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv('songs.csv')\n",
    "\n",
    "#only starting with 20 songs because the vocab size will be huge\n",
    "df_train = df.iloc[:50]\n",
    "df_train = df_train[['tags_tokenized','track_popularity']]\n",
    "train_data = DataProcessor(df_train, 15000)\n",
    "trainLoader = DataLoader(train_data, batch_size= 50, shuffle = True)\n",
    "DataProcessor\n",
    "vocabSize = len(train_data.word_to_id)\n",
    "nEmbed = 100\n",
    "nHidden = 200\n",
    "nLayers = 4\n",
    "print(vocabSize)\n",
    "RNN_1 = RNNmodel(vocabSize, nEmbed, nHidden, nLayers)\n",
    "batch_train(RNN_1, trainLoader, trainLoader, 20)\n",
    "\n",
    "# df2 = df1[['tags_tokenized','track_name','track_popularity']]\n",
    "# print(df2)\n",
    "print(evaluate(RNN_1, trainLoader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosc410",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
